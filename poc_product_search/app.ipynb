{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import classes\n",
    "from flask import Flask, render_template, json, request ,jsonify, redirect     # import flask\n",
    "from bs4 import BeautifulSoup\n",
    "from flask import *\n",
    "import requests\n",
    "from lxml import etree\n",
    "from lxml import html\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "import time \n",
    "# import libraties\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [16/Jan/2021 21:59:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [16/Jan/2021 22:00:10] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside search\n",
      "Macbook Pro 13inch\n",
      "Macbook Pro 13inch\n",
      "**************Amazon*****************\n",
      "inside amazon\n",
      "product Title =  NA\n",
      "Products price =  NA\n",
      "Overall rating =  NA\n",
      "Total reviews =  NA\n",
      "Availability =  NA\n",
      "**************Noon*****************\n"
     ]
    }
   ],
   "source": [
    "#Intitate Flask and handle all request and response\n",
    "app = Flask(__name__)             # create an app instance\n",
    "\n",
    "# @app.route(\"/<name>\")              # at the end point /<name>\n",
    "# def hello_name(name):              # call method hello_name\n",
    "#     return \"Hello \"+ name          # which returns \"hello + name \n",
    "# which returns \"hello world\"\n",
    "\n",
    "@app.route(\"/\")\n",
    "def main():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/search',methods=['POST'])\n",
    "def search():\n",
    "    # create user code will be here !!\n",
    "     # read the posted values from the UI\n",
    "    print('inside search')\n",
    "    textvalue = request.json['input']\n",
    "    print(textvalue)\n",
    "    output_df = callengine(textvalue)\n",
    "    output_df.to_csv('product_aggregation.csv', index=False)\n",
    "   \n",
    "    return jsonify({\"response\" : textvalue})\n",
    "\n",
    "\n",
    "@app.route('/results',methods=(\"GET\", \"POST\"))  \n",
    "def showresult():  \n",
    "    input_data = pd.read_csv('product_aggregation.csv', encoding='latin-1')\n",
    "    input_data['product_price'] = input_data['product_price'].str.replace(r'AED', '')\n",
    "    input_data['product_price'] = input_data['product_price'].str.replace(r'Ã‚', '')\n",
    "    input_data['product_price'] = input_data['product_price'].str.replace('(In Deal)', '')\n",
    "    input_data['product_price'] = input_data['product_price'].str.replace('\\nInclusive of VAT', '')\n",
    "    input_data['product_price'] = input_data['product_price'].str.replace(',', '')\n",
    "    input_data = input_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    input_data[\"product_price\"] = pd.to_numeric(input_data[\"product_price\"])\n",
    "    input_data = input_data.sort_values(by=['product_price'],ascending=True)\n",
    "    return render_template('simple.html',tables=[input_data.to_html()],\n",
    "    titles = ['na', 'Product Results'])\n",
    "    \n",
    "@app.after_request\n",
    "def add_headers(response):\n",
    "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')\n",
    "    return response    \n",
    "    \n",
    "if __name__ == \"__main__\":        #\n",
    "    app.run()\n",
    "    # run the flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to scrap data from amazon through Beautiful Soup\n",
    "def main_amazon(URL,product_df): \n",
    "    \n",
    "    print('inside amazon')\n",
    "    # specifying user agent, You can use other user agents \n",
    "    # available on the internet \n",
    "    HEADERS = ({'User-Agent': \n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36', \n",
    "                                'Accept-Language': 'en-US, en;q=0.5'}) \n",
    "    \n",
    "   # driver = webdriver.Chrome('Path in your computer where you have installed chromedriver')\n",
    "  \n",
    "    # Making the HTTP Request \n",
    "    webpage = requests.get(URL, headers=HEADERS) \n",
    "  \n",
    "    # Creating the Soup Object containing all data \n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\") \n",
    "  \n",
    "    # retreiving product title \n",
    "    try: \n",
    "        # Outer Tag Object \n",
    "        title = soup.find(\"span\",  \n",
    "                          attrs={\"id\": 'productTitle'}) \n",
    "  \n",
    "        # Inner NavigableString Object \n",
    "        title_value = title.string \n",
    "        # Title as a string value \n",
    "        title_string = title_value.strip().replace(',', '') \n",
    "  \n",
    "    except AttributeError: \n",
    "        title_string = \"NA\"\n",
    "    print(\"product Title = \", title_string) \n",
    "  \n",
    "    # saving the title in the file \n",
    "    #File.write(f\"{title_string},\") \n",
    "  \n",
    "    # retreiving price \n",
    "    try: \n",
    "        price = soup.find( \n",
    "            \"span\", attrs={'id': 'priceblock_ourprice'}).string.strip().replace(',', '') \n",
    "        # we are omitting unnecessary spaces \n",
    "        # and commas form our string \n",
    "    except AttributeError: \n",
    "        try:\n",
    "            price = soup.find( \n",
    "                \"span\", attrs={'id': 'priceblock_dealprice'}).string.strip().replace(',', '') \n",
    "            price = price\n",
    "            \n",
    "        except AttributeError:\n",
    "            price = \"NA\"\n",
    "        \n",
    "    print(\"Products price = \", price) \n",
    "  \n",
    "    # retreiving product rating \n",
    "    try: \n",
    "        rating = soup.find(\"i\", attrs={ \n",
    "                           'class': 'a-icon a-icon-star a-star-4-5'}).string.strip().replace(',', '') \n",
    "  \n",
    "    except AttributeError: \n",
    "  \n",
    "        try: \n",
    "            rating = soup.find( \n",
    "                \"span\", attrs={'class': 'a-icon-alt'}).string.strip().replace(',', '') \n",
    "        except: \n",
    "            rating = \"NA\"\n",
    "    rating = rating.replace('out of 5 stars','')\n",
    "    print(\"Overall rating = \", rating) \n",
    "  \n",
    "    #File.write(f\"{rating},\") \n",
    "  \n",
    "    try: \n",
    "        review_count = soup.find( \n",
    "            \"span\", attrs={'id': 'acrCustomerReviewText'}).string.strip().replace(',', '') \n",
    "  \n",
    "    except AttributeError: \n",
    "        review_count = \"NA\"\n",
    "    print(\"Total reviews = \", review_count) \n",
    "    #File.write(f\"{review_count},\") \n",
    "    \n",
    "    # print availiblility status \n",
    "    try: \n",
    "        available = soup.find(\"div\", attrs={'id': 'availability'}) \n",
    "        available = available.find(\"span\").string.strip().replace(',', '') \n",
    "  \n",
    "    except AttributeError: \n",
    "        available = \"NA\"\n",
    "    print(\"Availability = \", available) \n",
    "      \n",
    "    new_row = {'vendor':'amazon', 'product_title':title_string,\n",
    "               'product_price':price,'Rating':rating,'Reviews':review_count,'Availability':available}\n",
    "   \n",
    "    return product_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to scrap data from noon, using selenium as reviews and ratings are not present as static and in form of hyperlink\n",
    "def main_noon1(URL,driverpath,product_df):\n",
    "    # openning our output file in append mode \n",
    "    #File = open(\"out.csv\", \"a\") \n",
    "  \n",
    "    # specifying user agent, You can use other user agents \n",
    "    # available on the internet \n",
    "    HEADERS = ({'User-Agent': \n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36', \n",
    "                                'Accept-Language': 'en-US, en;q=0.5'}) \n",
    "    # Making the HTTP Request \n",
    "    webpage = requests.get(URL, headers=HEADERS) \n",
    "    # Creating the Soup Object containing all data \n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\") \n",
    "    driver = webdriver.Chrome(driverpath)\n",
    "   \n",
    "    driver.get(URL)\n",
    "    time.sleep(10)\n",
    "    #retreiving product title \n",
    "    try: \n",
    "        title = driver.find_elements_by_xpath('.//h1[@class=\"sc-1vbk2g0-8 cfCaBu\"]')[0].text\n",
    "  \n",
    "        #print(title)\n",
    "        # Inner NavigableString Object \n",
    "        title_value = title \n",
    "  \n",
    "        # Title as a string value \n",
    "        title_string = title_value.strip().replace(',', '') \n",
    "  \n",
    "    except AttributeError: \n",
    "        title_string = \"NA\"\n",
    "    print(\"product Title = \", title_string) \n",
    "\n",
    "  \n",
    "    #retreiving price \n",
    "    try: \n",
    "\n",
    "        price = driver.find_elements_by_xpath('.//div[@class=\"priceNow\"]')[0].text\n",
    "        price = price.replace('(Inclusive of VAT)','')\n",
    "        price = price. rstrip('\\n')\n",
    "        #price = price.text\n",
    "    except AttributeError: \n",
    "        price = \"NA\"\n",
    "    print(\"Products price = \", price) \n",
    "  \n",
    "\n",
    "    try: \n",
    "        available = driver.find_elements_by_xpath('.//div[@class=\"sc-1xw7r3i-0 grpnyI\"]')\n",
    "        #available = available.find(\"span\").string.strip().replace(',', '') \n",
    "        if (available.length==0):\n",
    "            available_string = 'In Stock.'\n",
    "        else:\n",
    "            available_string = 'Sorry! This product is not available.'\n",
    "    except AttributeError: \n",
    "        available_string = 'In Stock.'\n",
    "    print(\"Availability = \", available_string) \n",
    "\n",
    "    \n",
    "    #retreiving product rating\n",
    "    try:\n",
    "        element = driver.find_elements_by_xpath('.//button[@id=\"Reviews\"]')\n",
    "        element[0].click()\n",
    "    except ElementNotVisibleException:\n",
    "        pass\n",
    "    try:\n",
    "        rating = driver.find_elements_by_xpath('.//div[@class=\"overallRating\"]')[0].text\n",
    "    except AttributeError: \n",
    "        rating = \"NA\"\n",
    "    print(\"Overall rating = \", rating) \n",
    "    \n",
    "    #retreiving review count\n",
    "    try: \n",
    "        review_count = driver.find_elements_by_xpath('.//div[@class=\"basedOn\"]')[0].text\n",
    "    except AttributeError: \n",
    "        review_count = \"NA\"\n",
    "    review_count = review_count.replace('Based on ','')#Based on \n",
    "    print(\"Total reviews = \", review_count) \n",
    "    \n",
    "    # closing the file and driver\n",
    "    driver.close()\n",
    "    new_row = {'vendor':'noon', 'product_title':title_string,\n",
    "               'product_price':price,'Rating':rating,'Reviews':review_count,'Availability':available_string}\n",
    "   \n",
    "    return product_df.append(new_row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to scrap data from noon using beatuiful soup\n",
    "def main_sharafdg(URL,product_df): \n",
    "    \n",
    "    # specifying user agent, You can use other user agents \n",
    "    # available on the internet \n",
    "    HEADERS = ({'User-Agent': \n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36', \n",
    "                                'Accept-Language': 'en-US, en;q=0.5'}) \n",
    "    \n",
    "   # driver = webdriver.Chrome('Path in your computer where you have installed chromedriver')\n",
    "  \n",
    "    # Making the HTTP Request \n",
    "    webpage = requests.get(URL, headers=HEADERS) \n",
    "  \n",
    "    # Creating the Soup Object containing all data \n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\") \n",
    "  \n",
    "    # retreiving product title \n",
    "    try: \n",
    "        # Outer Tag Object \n",
    "        title = soup.find(\"h1\",  \n",
    "                          attrs={\"class\": 'product_title entry-title'}) \n",
    "  \n",
    "        # Inner NavigableString Object \n",
    "        title_value = title.string \n",
    "  \n",
    "        # Title as a string value \n",
    "        title_string = title_value.strip().replace(',', '') \n",
    "  \n",
    "    except AttributeError: \n",
    "        title_string = \"NA\"\n",
    "    print(\"product Title = \", title_string) \n",
    "  \n",
    "    # saving the title in the file \n",
    "    #File.write(f\"{title_string},\") \n",
    "  \n",
    "    # retreiving price \n",
    "    try: \n",
    "        currency = soup.find( \n",
    "            \"span\", attrs={'class': 'currency'}).string\n",
    "        price = soup.find( \n",
    "            \"span\", attrs={'class': 'total--sale-price'}).string\n",
    "        # we are omitting unnecessary spaces \n",
    "        # and commas form our string \n",
    "    except AttributeError: \n",
    "        price = \"NA\"\n",
    "    print(\"Products price = \", currency+' '+price) \n",
    "  \n",
    "    # saving \n",
    "    #File.write(f\"{price},\") \n",
    "  \n",
    "    # retreiving product rating \n",
    "    try: \n",
    "        rating = soup.find(\"span\", attrs={ \n",
    "                           'class': 'product-rating-count'}).string.strip().replace('(', '') .replace(')','')\n",
    "  \n",
    "    except AttributeError: \n",
    "        rating = \"NA\"\n",
    "    rating = rating.replace('out of 5 stars','')\n",
    "    print(\"Overall rating = \", rating) \n",
    "  \n",
    "    #File.write(f\"{rating},\") \n",
    "  \n",
    "    try: \n",
    "        review_count = soup.find( \n",
    "            \"span\", attrs={'itemprop': 'reviewCount'}).string.strip().replace(',', '') \n",
    "        review_count = review_count+\" ratings\"\n",
    "    except AttributeError: \n",
    "        review_count = \"NA\"\n",
    "    print(\"Total reviews = \", review_count) \n",
    "    #File.write(f\"{review_count},\") \n",
    "    \n",
    "    # print availiblility status \n",
    "    try: \n",
    "        available = soup.find(\"p\", attrs={'id': 'out-of-stock-box'}) \n",
    "        available = available.string\n",
    "  \n",
    "    except AttributeError: \n",
    "        available = \"In Stock\"\n",
    "    print(\"Availability = \", available) \n",
    "      \n",
    "    new_row = {'vendor':'sharafdg', 'product_title':title_string,\n",
    "               'product_price':currency+' '+price,'Rating':rating,'Reviews':review_count,'Availability':available}\n",
    "   \n",
    "    return product_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "#output_df = callengine('iPhone 11 Pro Max 256 GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = pd.read_csv('inputdata.csv', encoding='latin-1')\n",
    "# inputvalue = 'iPhone 11 Pro Max 256 GBB'\n",
    "# input_data.loc[input_data['keyword'] == inputvalue]\n",
    "# filter_data = input_data.loc[input_data['keyword'] == inputvalue]\n",
    "# filter_data.head()\n",
    "# if(filter_data.empty):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = pd.read_csv('product_aggregation.csv', encoding='latin-1')\n",
    "# input_data['product_price'] = input_data['product_price'].str.replace(r'AED', '')\n",
    "# input_data['product_price'] = input_data['product_price'].str.replace(r'Ã‚', '')\n",
    "# input_data['product_price'] = input_data['product_price'].str.replace('(In Deal)', '')\n",
    "# input_data['product_price'] = input_data['product_price'].str.replace('\\nInclusive of VAT', '')\n",
    "# input_data['product_price'] = input_data['product_price'].str.replace(',', '')\n",
    "# input_data = input_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "# #print (df)\n",
    "# input_data[\"product_price\"] = pd.to_numeric(input_data[\"product_price\"])\n",
    "# input_data = input_data.sort_values(by=['product_price'],ascending=True)\n",
    "# input_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engine to scrap all the data and insert into dataframe\n",
    "def callengine(inputvalue):\n",
    "    # Reading links_data file\n",
    "    print(inputvalue)\n",
    "    input_data = pd.read_csv('inputdata.csv', encoding='latin-1')\n",
    "    #inputvalue = 'Macbook Pro 13inch'\n",
    "    filter_data = input_data.loc[input_data['keyword'] == inputvalue]\n",
    "    #print(filter_data)\n",
    "    if filter_data.empty:\n",
    "        return filter_data\n",
    "    else:\n",
    "        cols = ['vendor','product_title','product_price','Rating','Reviews','Availability']\n",
    "        product_df = pd.DataFrame(columns = cols)\n",
    "        print('**************Amazon*****************')\n",
    "        product_df = main_amazon(filter_data['amazon'].item(),product_df)\n",
    "        print('**************Noon*****************')\n",
    "        driver_path = input_data.loc[input_data['keyword'] == 'chromedriver']\n",
    "        \n",
    "        product_df = main_noon1(filter_data['noon'].item(),driver_path['amazon'].item(),product_df)\n",
    "        print('**************SharafDG*************')\n",
    "        product_df = main_sharafdg(filter_data['sharafdg'].item(),product_df)\n",
    "        return product_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
